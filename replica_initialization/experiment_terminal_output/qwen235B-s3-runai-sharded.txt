INFO 10-15 15:30:04 [__init__.py:224] Automatically detected platform cuda.
[36m(ServeReplica:default:OpenAiIngress pid=329477)[0m INFO 10-15 15:30:49 [__init__.py:224] Automatically detected platform cuda.
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m INFO 10-15 15:30:54 [__init__.py:224] Automatically detected platform cuda.
[36m(download_model_files pid=329848)[0m INFO 10-15 15:31:01 [__init__.py:224] Automatically detected platform cuda.
[36m(_get_vllm_engine_config pid=329848)[0m INFO 10-15 15:31:05 [model.py:646] Resolved architecture: Qwen3MoeForCausalLM
[36m(_get_vllm_engine_config pid=329848)[0m INFO 10-15 15:31:06 [model.py:1734] Using max model len 40960
[36m(_get_vllm_engine_config pid=329848)[0m INFO 10-15 15:31:06 [arg_utils.py:1348] Using ray runtime env (env vars redacted): {'cgroupv2': {}, 'ray_debugger': {'working_dir': '/home/ray/default/workspace'}, 'working_dir': 'gcs://_ray_pkg_4acd27c7dbfa1a9ba5de2194407db4c6e728e9f9.zip', 'env_vars': {'AWS_ACCESS_KEY_ID': '***', 'AWS_SECRET_ACCESS_KEY': '***', 'AWS_SESSION_TOKEN': '***', 'VLLM_USE_V1': '***'}, 'worker_process_setup_hook': 'ray.llm._internal.serve._worker_process_setup_hook'}
[36m(_get_vllm_engine_config pid=329848)[0m INFO 10-15 15:31:06 [scheduler.py:225] Chunked prefill is enabled with max_num_batched_tokens=8192.
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m WARNING 10-15 15:31:07 [__init__.py:2881] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: In a Ray actor and can only be spawned
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m INFO 10-15 15:31:10 [__init__.py:224] Automatically detected platform cuda.
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:31:12 [core.py:734] Waiting for init message from front-end.
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:31:12 [core.py:97] Initializing a V1 LLM engine (v0.1.dev10446+g2dcd12d35) with config: model='/home/ray/.cache/vllm/assets/model_streamer/a65e7a19', speculative_config=None, tokenizer='/home/ray/.cache/vllm/assets/model_streamer/a65e7a19', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=runai_streamer_sharded, tensor_parallel_size=8, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=llama, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={'level': 3, 'debug_dump_path': None, 'cache_dir': '', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention', 'vllm::sparse_attn_indexer'], 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'use_cudagraph': True, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [512, 504, 496, 488, 480, 472, 464, 456, 448, 440, 432, 424, 416, 408, 400, 392, 384, 376, 368, 360, 352, 344, 336, 328, 320, 312, 304, 296, 288, 280, 272, 264, 256, 248, 240, 232, 224, 216, 208, 200, 192, 184, 176, 168, 160, 152, 144, 136, 128, 120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 4, 2, 1], 'cudagraph_copy_inputs': False, 'full_cuda_graph': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_capture_size': 512, 'local_cache_dir': None}
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:31:12 [ray_utils.py:351] Using the existing placement group
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:31:12 [ray_distributed_executor.py:180] use_ray_spmd_worker: True
[36m(pid=330269)[0m INFO 10-15 15:31:18 [__init__.py:224] Automatically detected platform cuda.
[36m(pid=330267)[0m INFO 10-15 15:31:18 [__init__.py:224] Automatically detected platform cuda.
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:31:23 [ray_env.py:66] RAY_NON_CARRY_OVER_ENV_VARS from config: set()
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:31:23 [ray_env.py:69] Copying the following environment variables to workers: ['LD_LIBRARY_PATH', 'VLLM_USE_RAY_SPMD_WORKER', 'VLLM_USE_V1', 'VLLM_USE_RAY_COMPILED_DAG', 'VLLM_WORKER_MULTIPROC_METHOD']
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:31:23 [ray_env.py:74] If certain env vars should NOT be copied, add them to /home/ray/.config/vllm/ray_non_carry_over_env_vars.json file
[36m(RayWorkerWrapper pid=330269)[0m WARNING 10-15 15:31:34 [worker_base.py:309] Missing `shared_worker_lock` argument from executor. This argument is needed for mm_processor_cache_type='shm'.
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(pid=330269)[0m INFO 10-15 15:31:18 [__init__.py:224] Automatically detected platform cuda.[32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=330270)[0m [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[36m(RayWorkerWrapper pid=330270)[0m [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[36m(RayWorkerWrapper pid=330269)[0m INFO 10-15 15:31:38 [pynccl.py:111] vLLM is using nccl==2.27.3
[36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:31:43 [custom_all_reduce.py:37] Skipping P2P check and trusting the driver's P2P report.
[36m(RayWorkerWrapper pid=330273)[0m WARNING 10-15 15:31:35 [worker_base.py:309] Missing `shared_worker_lock` argument from executor. This argument is needed for mm_processor_cache_type='shm'.[32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=330270)[0m [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7[32m [repeated 18x across cluster][0m
[36m(RayWorkerWrapper pid=330269)[0m INFO 10-15 15:31:43 [shm_broadcast.py:302] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3, 4, 5, 6, 7], buffer_handle=(7, 4194304, 6, 'psm_0475d642'), local_subscribe_addr='ipc:///tmp/f7f3cb96-a39f-4005-9802-cd122762edfc', remote_subscribe_addr=None, remote_addr_ipv6=False)
[36m(RayWorkerWrapper pid=330269)[0m INFO 10-15 15:31:43 [pynccl.py:111] vLLM is using nccl==2.27.3
[36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:31:46 [parallel_state.py:1325] rank 3 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 3, EP rank 3
[36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:31:46 [topk_topp_sampler.py:58] Using FlashInfer for top-p & top-k sampling.
[36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:31:47 [gpu_model_runner.py:2845] Starting to load model /home/ray/.cache/vllm/assets/model_streamer/a65e7a19...
[36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:31:47 [cuda.py:405] Using Flash Attention backend on V1 engine.
[36m(RayWorkerWrapper pid=330270)[0m [RunAI Streamer] CPU Buffer size: 96 Bytes for files: ['s3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-0.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-1.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-10.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-11.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-2.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-3.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-4.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-5.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-6.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-7.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-8.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-9.safetensors']
[36m(RayWorkerWrapper pid=330270)[0m [RunAI Streamer] CPU Buffer size: 95.6 KiB for files: ['s3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-1.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-11.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-3.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-6.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-8.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-7.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-10.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-0.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-9.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-4.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-5.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-2.safetensors']
[36m(RayWorkerWrapper pid=330270)[0m [RunAI Streamer] CPU Buffer size: 18.6 GiB for files: ['s3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-0.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-1.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-10.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-11.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-2.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-3.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-4.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-5.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-6.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-7.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-8.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-9.safetensors']
[36m(RayWorkerWrapper pid=330270)[0m Read throughput is 794.22 MB per second 
[36m(RayWorkerWrapper pid=330267)[0m INFO 10-15 15:31:43 [custom_all_reduce.py:37] Skipping P2P check and trusting the driver's P2P report.[32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=330267)[0m [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7[32m [repeated 28x across cluster][0m
[36m(RayWorkerWrapper pid=330267)[0m INFO 10-15 15:31:46 [parallel_state.py:1325] rank 6 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 6, EP rank 6[32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=330269)[0m INFO 10-15 15:31:47 [topk_topp_sampler.py:58] Using FlashInfer for top-p & top-k sampling.[32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=330267)[0m INFO 10-15 15:31:47 [gpu_model_runner.py:2845] Starting to load model /home/ray/.cache/vllm/assets/model_streamer/a65e7a19...[32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=330269)[0m INFO 10-15 15:31:47 [cuda.py:405] Using Flash Attention backend on V1 engine.[32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=330269)[0m [RunAI Streamer] CPU Buffer size: 96 Bytes for files: ['s3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-0.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-1.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-10.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-11.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-2.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-3.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-4.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-5.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-6.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-7.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-8.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-9.safetensors'][32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=330267)[0m [RunAI Streamer] CPU Buffer size: 95.6 KiB for files: ['s3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-6.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-1.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-8.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-0.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-7.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-4.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-2.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-11.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-10.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-9.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-5.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-3.safetensors'][32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=330267)[0m [RunAI Streamer] CPU Buffer size: 18.6 GiB for files: ['s3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-0.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-1.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-10.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-11.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-2.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-3.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-4.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-5.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-6.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-7.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-8.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-9.safetensors'][32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330269)[0m WARNING 10-15 15:31:34 [worker_base.py:309] Missing `shared_worker_lock` argument from executor. This argument is needed for mm_processor_cache_type='shm'.
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(pid=330274)[0m INFO 10-15 15:31:19 [__init__.py:224] Automatically detected platform cuda.[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330269)[0m INFO 10-15 15:31:38 [pynccl.py:111] vLLM is using nccl==2.27.3
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330273)[0m WARNING 10-15 15:31:35 [worker_base.py:309] Missing `shared_worker_lock` argument from executor. This argument is needed for mm_processor_cache_type='shm'.[32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330270)[0m [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7[32m [repeated 18x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330269)[0m INFO 10-15 15:31:43 [shm_broadcast.py:302] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3, 4, 5, 6, 7], buffer_handle=(7, 4194304, 6, 'psm_0475d642'), local_subscribe_addr='ipc:///tmp/f7f3cb96-a39f-4005-9802-cd122762edfc', remote_subscribe_addr=None, remote_addr_ipv6=False)
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330269)[0m INFO 10-15 15:31:43 [pynccl.py:111] vLLM is using nccl==2.27.3
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330267)[0m INFO 10-15 15:31:43 [custom_all_reduce.py:37] Skipping P2P check and trusting the driver's P2P report.[32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330267)[0m [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7[32m [repeated 28x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330267)[0m INFO 10-15 15:31:46 [parallel_state.py:1325] rank 6 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 6, EP rank 6[32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330269)[0m INFO 10-15 15:31:47 [topk_topp_sampler.py:58] Using FlashInfer for top-p & top-k sampling.[32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330267)[0m INFO 10-15 15:31:47 [gpu_model_runner.py:2845] Starting to load model /home/ray/.cache/vllm/assets/model_streamer/a65e7a19...[32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330269)[0m INFO 10-15 15:31:47 [cuda.py:405] Using Flash Attention backend on V1 engine.[32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330269)[0m [RunAI Streamer] CPU Buffer size: 96 Bytes for files: ['s3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-0.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-1.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-10.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-11.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-2.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-3.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-4.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-5.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-6.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-7.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-8.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-0-part-9.safetensors'][32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=330274)[0m Read throughput is 654.74 MB per second [32m [repeated 8x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:31:43 [custom_all_reduce.py:37] Skipping P2P check and trusting the driver's P2P report.
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330270)[0m [Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7[32m [repeated 2x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:31:46 [parallel_state.py:1325] rank 3 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 3, EP rank 3
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:31:46 [topk_topp_sampler.py:58] Using FlashInfer for top-p & top-k sampling.
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:31:47 [gpu_model_runner.py:2845] Starting to load model /home/ray/.cache/vllm/assets/model_streamer/a65e7a19...
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:31:47 [cuda.py:405] Using Flash Attention backend on V1 engine.
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330270)[0m [RunAI Streamer] CPU Buffer size: 96 Bytes for files: ['s3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-0.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-1.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-10.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-11.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-2.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-3.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-4.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-5.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-6.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-7.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-8.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-9.safetensors']
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330270)[0m [RunAI Streamer] CPU Buffer size: 95.6 KiB for files: ['s3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-1.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-11.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-3.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-6.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-8.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-7.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-10.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-0.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-9.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-4.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-5.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-2.safetensors']
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330270)[0m [RunAI Streamer] CPU Buffer size: 18.6 GiB for files: ['s3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-0.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-1.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-10.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-11.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-2.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-3.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-4.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-5.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-6.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-7.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-8.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-3-part-9.safetensors']
[36m(RayWorkerWrapper pid=330272)[0m Read throughput is 802.57 MB per second 
[36m(RayWorkerWrapper pid=330268)[0m Read throughput is 881.94 MB per second 
[36m(RayWorkerWrapper pid=330273)[0m Read throughput is 603.66 MB per second [32m [repeated 6x across cluster][0m
[36m(RayWorkerWrapper pid=330274)[0m [RunAI Streamer] Overall time to stream 54.9 GiB of all files: 74.29s, 756.8 MiB/s
[36m(RayWorkerWrapper pid=330274)[0m Read throughput is 905.54 MB per second 
[36m(RayWorkerWrapper pid=330272)[0m Read throughput is 815.35 MB per second 
[36m(RayWorkerWrapper pid=330272)[0m INFO 10-15 15:33:03 [gpu_model_runner.py:2906] Model loading took 54.9205 GiB and 75.391083 seconds
[36m(RayWorkerWrapper pid=330273)[0m Read throughput is 1.14 GB per second 
[36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:33:22 [backends.py:608] Using cache directory: /home/ray/.cache/vllm/torch_compile_cache/7df9ff8bee/rank_3_0/backbone for vLLM's torch.compile
[36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:33:22 [backends.py:622] Dynamo bytecode transform time: 17.17 s
[36m(RayWorkerWrapper pid=330268)[0m [RunAI Streamer] Overall time to stream 54.9 GiB of all files: 76.63s, 733.8 MiB/s[32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=330268)[0m Read throughput is 754.88 MB per second [32m [repeated 5x across cluster][0m
[36m(RayWorkerWrapper pid=330268)[0m INFO 10-15 15:33:05 [gpu_model_runner.py:2906] Model loading took 54.9205 GiB and 77.521401 seconds[32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:33:27 [backends.py:247] Cache the graph for dynamic shape for later use
[36m(RayWorkerWrapper pid=330273)[0m INFO 10-15 15:33:23 [backends.py:608] Using cache directory: /home/ray/.cache/vllm/torch_compile_cache/7df9ff8bee/rank_7_0/backbone for vLLM's torch.compile[32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=330273)[0m INFO 10-15 15:33:23 [backends.py:622] Dynamo bytecode transform time: 18.03 s[32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=330269)[0m INFO 10-15 15:34:58 [backends.py:274] Compiling a graph for dynamic shape takes 93.80 s
[36m(RayWorkerWrapper pid=330273)[0m INFO 10-15 15:33:28 [backends.py:247] Cache the graph for dynamic shape for later use[32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:35:04 [fused_moe.py:863] Using configuration from /home/ray/default/repo/vllm/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json for MoE layer.
[36m(RayWorkerWrapper pid=330272)[0m INFO 10-15 15:35:01 [backends.py:274] Compiling a graph for dynamic shape takes 97.34 s[32m [repeated 7x across cluster][0m
[36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:35:05 [monitor.py:33] torch.compile takes 113.22 s in total
[36m(RayWorkerWrapper pid=330267)[0m INFO 10-15 15:35:09 [gpu_worker.py:315] Available KV cache memory: 13.22 GiB
[36m(RayWorkerWrapper pid=330267)[0m INFO 10-15 15:35:04 [fused_moe.py:863] Using configuration from /home/ray/default/repo/vllm/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json for MoE layer.[32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m 
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330267)[0m [RunAI Streamer] CPU Buffer size: 95.6 KiB for files: ['s3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-6.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-1.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-8.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-0.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-7.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-4.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-2.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-11.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-10.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-9.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-5.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-3.safetensors'][32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330267)[0m [RunAI Streamer] CPU Buffer size: 18.6 GiB for files: ['s3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-0.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-1.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-10.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-11.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-2.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-3.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-4.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-5.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-6.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-7.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-8.safetensors', 's3://ahao-runai-east1/Qwen3-235B-A22B-sharded/model-rank-6-part-9.safetensors'][32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330274)[0m Read throughput is 654.74 MB per second [32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330272)[0m Read throughput is 802.57 MB per second 
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330268)[0m Read throughput is 881.94 MB per second 
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330273)[0m Read throughput is 603.66 MB per second [32m [repeated 6x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330274)[0m [RunAI Streamer] Overall time to stream 54.9 GiB of all files: 74.29s, 756.8 MiB/s
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330274)[0m Read throughput is 905.54 MB per second 
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330272)[0m Read throughput is 815.35 MB per second 
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330272)[0m INFO 10-15 15:33:03 [gpu_model_runner.py:2906] Model loading took 54.9205 GiB and 75.391083 seconds
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330273)[0m Read throughput is 1.14 GB per second 
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:33:22 [backends.py:608] Using cache directory: /home/ray/.cache/vllm/torch_compile_cache/7df9ff8bee/rank_3_0/backbone for vLLM's torch.compile
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:33:22 [backends.py:622] Dynamo bytecode transform time: 17.17 s
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330268)[0m [RunAI Streamer] Overall time to stream 54.9 GiB of all files: 76.63s, 733.8 MiB/s[32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330268)[0m Read throughput is 754.88 MB per second [32m [repeated 5x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330268)[0m INFO 10-15 15:33:05 [gpu_model_runner.py:2906] Model loading took 54.9205 GiB and 77.521401 seconds[32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:33:27 [backends.py:247] Cache the graph for dynamic shape for later use
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330273)[0m INFO 10-15 15:33:23 [backends.py:608] Using cache directory: /home/ray/.cache/vllm/torch_compile_cache/7df9ff8bee/rank_7_0/backbone for vLLM's torch.compile[32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330273)[0m INFO 10-15 15:33:23 [backends.py:622] Dynamo bytecode transform time: 18.03 s[32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330269)[0m INFO 10-15 15:34:58 [backends.py:274] Compiling a graph for dynamic shape takes 93.80 s
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330273)[0m INFO 10-15 15:33:28 [backends.py:247] Cache the graph for dynamic shape for later use[32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330272)[0m INFO 10-15 15:35:01 [backends.py:274] Compiling a graph for dynamic shape takes 97.34 s[32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330267)[0m INFO 10-15 15:35:04 [fused_moe.py:863] Using configuration from /home/ray/default/repo/vllm/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json for MoE layer.[32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:10 [kv_cache_utils.py:1199] GPU KV cache size: 294,992 tokens
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:10 [kv_cache_utils.py:1204] Maximum concurrency for 40,960 tokens per request: 7.20x
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:10 [kv_cache_utils.py:1199] GPU KV cache size: 294,992 tokens
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:10 [kv_cache_utils.py:1204] Maximum concurrency for 40,960 tokens per request: 7.20x
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:10 [kv_cache_utils.py:1199] GPU KV cache size: 294,992 tokens
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:10 [kv_cache_utils.py:1204] Maximum concurrency for 40,960 tokens per request: 7.20x
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:10 [kv_cache_utils.py:1199] GPU KV cache size: 294,992 tokens
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:10 [kv_cache_utils.py:1204] Maximum concurrency for 40,960 tokens per request: 7.20x
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:10 [kv_cache_utils.py:1199] GPU KV cache size: 294,992 tokens
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:10 [kv_cache_utils.py:1204] Maximum concurrency for 40,960 tokens per request: 7.20x
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:10 [kv_cache_utils.py:1199] GPU KV cache size: 294,992 tokens
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:10 [kv_cache_utils.py:1204] Maximum concurrency for 40,960 tokens per request: 7.20x
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:10 [kv_cache_utils.py:1199] GPU KV cache size: 294,992 tokens
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:10 [kv_cache_utils.py:1204] Maximum concurrency for 40,960 tokens per request: 7.20x
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:10 [kv_cache_utils.py:1199] GPU KV cache size: 294,992 tokens
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:10 [kv_cache_utils.py:1204] Maximum concurrency for 40,960 tokens per request: 7.20x
[36m(RayWorkerWrapper pid=330269)[0m INFO 10-15 15:35:54 [custom_all_reduce.py:216] Registering 2268 cuda graph addresses
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:35:05 [monitor.py:33] torch.compile takes 113.22 s in total[32m [repeated 8x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330267)[0m INFO 10-15 15:35:09 [gpu_worker.py:315] Available KV cache memory: 13.22 GiB[32m [repeated 8x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:35:04 [fused_moe.py:863] Using configuration from /home/ray/default/repo/vllm/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json for MoE layer.
[36m(RayWorkerWrapper pid=330270)[0m INFO 10-15 15:35:55 [gpu_model_runner.py:3816] Graph capturing finished in 44 secs, took 2.99 GiB
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330267)[0m INFO 10-15 15:35:05 [monitor.py:33] torch.compile takes 112.31 s in total[32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m [36m(RayWorkerWrapper pid=330268)[0m INFO 10-15 15:35:10 [gpu_worker.py:315] Available KV cache memory: 13.22 GiB[32m [repeated 7x across cluster][0m
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:56 [core.py:243] init engine (profile, create kv cache, warmup model) took 170.53 seconds
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:56 [gc_utils.py:40] GC Debug Config. enabled:False,top_objects:-1
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m INFO 10-15 15:35:56 [loggers.py:191] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 18437
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m INFO 10-15 15:35:56 [api_server.py:1629] Supported tasks: ['generate']
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m WARNING 10-15 15:35:56 [model.py:1591] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m INFO 10-15 15:35:56 [serving_responses.py:148] Using default chat sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m INFO 10-15 15:35:56 [serving_chat.py:130] Using default chat sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m INFO 10-15 15:35:56 [serving_completion.py:67] Using default completion sampling params from model: {'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m INFO 10-15 15:35:57 [chat_utils.py:545] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m INFO 10-15 15:35:57 [async_llm.py:344] Added request chatcmpl-2a3f08c6-5cd2-4049-9edb-3a6b582fa3e2.
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:57 [ray_distributed_executor.py:570] RAY_CGRAPH_get_timeout is set to 300
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:57 [ray_distributed_executor.py:574] VLLM_USE_RAY_COMPILED_DAG_CHANNEL_TYPE = auto
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:57 [ray_distributed_executor.py:578] VLLM_USE_RAY_COMPILED_DAG_OVERLAP_COMM = False
[36m(ServeReplica:default:LLMServer:llama pid=329663)[0m [1;36m(EngineCore_DP0 pid=330089)[0;0m INFO 10-15 15:35:57 [ray_distributed_executor.py:654] Using RayPPCommunicator (which wraps vLLM _PP GroupCoordinator) for Ray Compiled Graph communication.
